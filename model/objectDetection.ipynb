{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상불러와서 OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "def detect_objects_on_video(video_path, model, threshold=0.5):\n",
    "    # 비디오를 열고 비디오의 프레임을 처리합니다.\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # OpenCV는 BGR을 사용하지만, PyTorch는 RGB를 사용하므로 색상을 변환합니다.\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # 이미지를 PIL 이미지로 변환합니다.\n",
    "            pil_image = Image.fromarray(frame)\n",
    "            # 모델을 호출하기 전에 이미지를 텐서로 변환합니다.\n",
    "            tensor_image = F.to_tensor(pil_image).unsqueeze(0)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                tensor_image = tensor_image.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # 모델 예측\n",
    "                prediction = model(tensor_image)\n",
    "\n",
    "            # 이제 프레임에 객체 검출을 시각화할 수 있습니다.\n",
    "            # 예를 들어, bounding box와 함께 객체를 그립니다.\n",
    "            for i in range(prediction[0]['boxes'].shape[0]):\n",
    "                if prediction[0]['scores'][i] > threshold:\n",
    "                    box = prediction[0]['boxes'][i].cpu().numpy().astype(int)\n",
    "                    cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "\n",
    "            # 결과를 보여줍니다.\n",
    "            cv2.imshow('frame', frame)\n",
    "\n",
    "            # 'q' 키를 누르면 종료합니다.\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 모델 로드\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 객체 검출 실행\n",
    "detect_objects_on_video('path_to_your_video.mp4', model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 내장카메라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "def detect_objects_on_webcam(model, threshold=0.5):\n",
    "    # 웹캠으로부터 비디오를 캡처합니다.\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # OpenCV는 BGR을 사용하지만, PyTorch는 RGB를 사용하므로 색상을 변환합니다.\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # 이미지를 PIL 이미지로 변환합니다.\n",
    "            pil_image = Image.fromarray(frame)\n",
    "            # 모델을 호출하기 전에 이미지를 텐서로 변환합니다.\n",
    "            tensor_image = F.to_tensor(pil_image).unsqueeze(0)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                tensor_image = tensor_image.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # 모델 예측\n",
    "                prediction = model(tensor_image)\n",
    "\n",
    "            # 이제 프레임에 객체 검출을 시각화할 수 있습니다.\n",
    "            # 예를 들어, bounding box와 함께 객체를 그립니다.\n",
    "            for i in range(prediction[0]['boxes'].shape[0]):\n",
    "                if prediction[0]['scores'][i] > threshold:\n",
    "                    box = prediction[0]['boxes'][i].cpu().numpy().astype(int)\n",
    "                    cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "\n",
    "            # 결과를 보여줍니다.\n",
    "            cv2.imshow('frame', frame)\n",
    "\n",
    "            # 'q' 키를 누르면 종료합니다.\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 모델 로드\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 웹캠에서 객체 검출을 실행\n",
    "detect_objects_on_webcam(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
