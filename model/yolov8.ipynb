{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https:\\github.com\\ultralytics\\assets\\releases\\download\\v0.0.0\\yolov8n.pt to yolov8n.pt...\n",
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 14.9MB/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m# Predict using the YOLO model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(frame)\n\u001b[0;32m     22\u001b[0m \u001b[39m# Iterate over each detection\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(results\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\ultralytics\\engine\\model.py:248\u001b[0m, in \u001b[0;36mYOLO.predict\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor:\n\u001b[0;32m    247\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask \u001b[39m=\u001b[39m overrides\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\n\u001b[1;32m--> 248\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor \u001b[39m=\u001b[39m TASK_MAP[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask][\u001b[39m3\u001b[39;49m](overrides\u001b[39m=\u001b[39;49moverrides, _callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks)\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39msetup_model(model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, verbose\u001b[39m=\u001b[39mis_cli)\n\u001b[0;32m    250\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# only update args if predictor is already setup\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\ultralytics\\engine\\predictor.py:108\u001b[0m, in \u001b[0;36mBasePredictor.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks \u001b[39m=\u001b[39m _callbacks \u001b[39mor\u001b[39;00m callbacks\u001b[39m.\u001b[39mget_default_callbacks()\n\u001b[1;32m--> 108\u001b[0m callbacks\u001b[39m.\u001b[39;49madd_integration_callbacks(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\ultralytics\\utils\\callbacks\\base.py:206\u001b[0m, in \u001b[0;36madd_integration_callbacks\u001b[1;34m(instance)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mneptune\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks \u001b[39mas\u001b[39;00m neptune_cb\n\u001b[0;32m    205\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mraytune\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks \u001b[39mas\u001b[39;00m tune_cb\n\u001b[1;32m--> 206\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks \u001b[39mas\u001b[39;00m tensorboard_cb\n\u001b[0;32m    207\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwb\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks \u001b[39mas\u001b[39;00m wb_cb\n\u001b[0;32m    209\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m clearml_cb, comet_cb, hub_cb, mlflow_cb, neptune_cb, tune_cb, tensorboard_cb, wb_cb, dvc_cb:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\ultralytics\\utils\\callbacks\\tensorboard.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39multralytics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m LOGGER, TESTS_RUNNING, colorstr\n\u001b[0;32m      5\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m \u001b[39mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m      8\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m TESTS_RUNNING  \u001b[39m# do not log pytest\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mImportError\u001b[39;00m, \u001b[39mAssertionError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdel\u001b[39;00m LooseVersion\n\u001b[0;32m     10\u001b[0m \u001b[39mdel\u001b[39;00m tensorboard\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwriter\u001b[39;00m \u001b[39mimport\u001b[39;00m FileWriter, SummaryWriter  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummary\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwriter\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrecord_writer\u001b[39;00m \u001b[39mimport\u001b[39;00m RecordWriter  \u001b[39m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m tf\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevent_pb2\u001b[39;00m \u001b[39mimport\u001b[39;00m SessionLog\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevent_pb2\u001b[39;00m \u001b[39mimport\u001b[39;00m Event\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m event_pb2\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\tensorboard\\compat\\proto\\event_pb2.py:17\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m summary_pb2 \u001b[39mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_summary__pb2\n\u001b[0;32m     20\u001b[0m DESCRIPTOR \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mFileDescriptor(\n\u001b[0;32m     21\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard/compat/proto/event.proto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m   package\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m   ,\n\u001b[0;32m     27\u001b[0m   dependencies\u001b[39m=\u001b[39m[tensorboard_dot_compat_dot_proto_dot_summary__pb2\u001b[39m.\u001b[39mDESCRIPTOR,])\n\u001b[0;32m     29\u001b[0m _WORKERHEALTH \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mEnumDescriptor(\n\u001b[0;32m     30\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mWorkerHealth\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard.WorkerHealth\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m1319\u001b[39m,\n\u001b[0;32m     56\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\tensorboard\\compat\\proto\\summary_pb2.py:17\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_pb2 \u001b[39mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_tensor__pb2\n\u001b[0;32m     20\u001b[0m DESCRIPTOR \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mFileDescriptor(\n\u001b[0;32m     21\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard/compat/proto/summary.proto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m   package\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m   ,\n\u001b[0;32m     27\u001b[0m   dependencies\u001b[39m=\u001b[39m[tensorboard_dot_compat_dot_proto_dot_tensor__pb2\u001b[39m.\u001b[39mDESCRIPTOR,])\n\u001b[0;32m     29\u001b[0m _DATACLASS \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mEnumDescriptor(\n\u001b[0;32m     30\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDataClass\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard.DataClass\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m1228\u001b[39m,\n\u001b[0;32m     56\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\tensorboard\\compat\\proto\\tensor_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m resource_handle_pb2 \u001b[39mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_resource__handle__pb2\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_types__pb2\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\tensorboard\\compat\\proto\\resource_handle_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_types__pb2\n\u001b[0;32m     20\u001b[0m DESCRIPTOR \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mFileDescriptor(\n\u001b[0;32m     21\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard/compat/proto/resource_handle.proto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m   package\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m   ,\n\u001b[0;32m     27\u001b[0m   dependencies\u001b[39m=\u001b[39m[tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\u001b[39m.\u001b[39mDESCRIPTOR,tensorboard_dot_compat_dot_proto_dot_types__pb2\u001b[39m.\u001b[39mDESCRIPTOR,])\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\tensorboard\\compat\\proto\\tensor_shape_pb2.py:36\u001b[0m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[0;32m     18\u001b[0m DESCRIPTOR \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mFileDescriptor(\n\u001b[0;32m     19\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard/compat/proto/tensor_shape.proto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m   package\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m   serialized_pb\u001b[39m=\u001b[39m_b(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m+tensorboard/compat/proto/tensor_shape.proto\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x0b\u001b[39;00m\u001b[39mtensorboard\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x10\u001b[39;00m\u001b[39mTensorShapeProto\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x64\u001b[39;00m\u001b[39mim\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x02\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x03\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x0b\u001b[39;00m\u001b[39m\\x32\u001b[39;00m\u001b[39m!.tensorboard.TensorShapeProto.Dim\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x14\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39munknown_rank\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x08\u001b[39;00m\u001b[39m\\x1a\u001b[39;00m\u001b[39m!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x44\u001b[39;00m\u001b[39mim\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x04\u001b[39;00m\u001b[39msize\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x04\u001b[39;00m\u001b[39mname\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x02\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mB\u001b[39m\u001b[39m\\x87\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x18\u001b[39;00m\u001b[39morg.tensorflow.frameworkB\u001b[39m\u001b[39m\\x11\u001b[39;00m\u001b[39mTensorShapeProtosP\u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39mZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\u001b[39m\u001b[39m\\xf8\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\x62\u001b[39;00m\u001b[39m\\x06\u001b[39;00m\u001b[39mproto3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     29\u001b[0m _TENSORSHAPEPROTO_DIM \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mDescriptor(\n\u001b[0;32m     30\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDim\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard.TensorShapeProto.Dim\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     32\u001b[0m   filename\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m   file\u001b[39m=\u001b[39mDESCRIPTOR,\n\u001b[0;32m     34\u001b[0m   containing_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     35\u001b[0m   fields\u001b[39m=\u001b[39m[\n\u001b[1;32m---> 36\u001b[0m     _descriptor\u001b[39m.\u001b[39;49mFieldDescriptor(\n\u001b[0;32m     37\u001b[0m       name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msize\u001b[39;49m\u001b[39m'\u001b[39;49m, full_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtensorboard.TensorShapeProto.Dim.size\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     38\u001b[0m       number\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, cpp_type\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     39\u001b[0m       has_default_value\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, default_value\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     40\u001b[0m       message_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, enum_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, containing_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     41\u001b[0m       is_extension\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, extension_scope\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     42\u001b[0m       serialized_options\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, file\u001b[39m=\u001b[39;49mDESCRIPTOR),\n\u001b[0;32m     43\u001b[0m     _descriptor\u001b[39m.\u001b[39mFieldDescriptor(\n\u001b[0;32m     44\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard.TensorShapeProto.Dim.name\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     45\u001b[0m       number\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, cpp_type\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     46\u001b[0m       has_default_value\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, default_value\u001b[39m=\u001b[39m_b(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     47\u001b[0m       message_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, enum_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, containing_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m       is_extension\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, extension_scope\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m       serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, file\u001b[39m=\u001b[39mDESCRIPTOR),\n\u001b[0;32m     50\u001b[0m   ],\n\u001b[0;32m     51\u001b[0m   extensions\u001b[39m=\u001b[39m[\n\u001b[0;32m     52\u001b[0m   ],\n\u001b[0;32m     53\u001b[0m   nested_types\u001b[39m=\u001b[39m[],\n\u001b[0;32m     54\u001b[0m   enum_types\u001b[39m=\u001b[39m[\n\u001b[0;32m     55\u001b[0m   ],\n\u001b[0;32m     56\u001b[0m   serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     57\u001b[0m   is_extendable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     58\u001b[0m   syntax\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mproto3\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     59\u001b[0m   extension_ranges\u001b[39m=\u001b[39m[],\n\u001b[0;32m     60\u001b[0m   oneofs\u001b[39m=\u001b[39m[\n\u001b[0;32m     61\u001b[0m   ],\n\u001b[0;32m     62\u001b[0m   serialized_start\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m,\n\u001b[0;32m     63\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m183\u001b[39m,\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     66\u001b[0m _TENSORSHAPEPROTO \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mDescriptor(\n\u001b[0;32m     67\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTensorShapeProto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     68\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorboard.TensorShapeProto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m183\u001b[39m,\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    103\u001b[0m _TENSORSHAPEPROTO_DIM\u001b[39m.\u001b[39mcontaining_type \u001b[39m=\u001b[39m _TENSORSHAPEPROTO\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\google\\protobuf\\descriptor.py:561\u001b[0m, in \u001b[0;36mFieldDescriptor.__new__\u001b[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, name, full_name, index, number, \u001b[39mtype\u001b[39m, cpp_type, label,\n\u001b[0;32m    556\u001b[0m             default_value, message_type, enum_type, containing_type,\n\u001b[0;32m    557\u001b[0m             is_extension, extension_scope, options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    558\u001b[0m             serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    559\u001b[0m             has_default_value\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, containing_oneof\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    560\u001b[0m             file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, create_key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m   _message\u001b[39m.\u001b[39;49mMessage\u001b[39m.\u001b[39;49m_CheckCalledFromGeneratedFile()\n\u001b[0;32m    562\u001b[0m   \u001b[39mif\u001b[39;00m is_extension:\n\u001b[0;32m    563\u001b[0m     \u001b[39mreturn\u001b[39;00m _message\u001b[39m.\u001b[39mdefault_pool\u001b[39m.\u001b[39mFindExtensionByName(full_name)\n",
      "\u001b[1;31mTypeError\u001b[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Create a YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Open the file to save detection results\n",
    "f = open(\"object_locations.txt\", \"w\")\n",
    "\n",
    "while True:\n",
    "    # Read one frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Predict using the YOLO model\n",
    "    results = model.predict(frame)\n",
    "\n",
    "    # Iterate over each detection\n",
    "    for i in range(results.shape[1]):\n",
    "        detection = results[0][i]\n",
    "        \n",
    "        # Here we are assuming that the first 4 elements are the bounding box coordinates,\n",
    "        # the 5th element is the objectness score, and the rest are the class scores.\n",
    "        bbox = detection[:4]\n",
    "        objectness = detection[4]\n",
    "        class_scores = detection[5:]\n",
    "        \n",
    "        # Find the class with the highest score\n",
    "        class_id = np.argmax(class_scores)\n",
    "        class_score = class_scores[class_id]\n",
    "\n",
    "        # We will consider the detection valid if the confidence score is greater than 0.85\n",
    "        if class_score > 0.85:\n",
    "            # Write to file, draw bounding boxes, etc.\n",
    "            # Note that the bbox coordinates will depend on how they are represented in the output.\n",
    "            # For example, they could be [center_x, center_y, width, height] or [x1, y1, x2, y2].\n",
    "            f.write(f\"Class: {class_id}, BBox: {bbox}\\n\")\n",
    "\n",
    "            # Draw the bounding box\n",
    "            # Note that we are assuming the bbox coordinates are in the format [center_x, center_y, width, height].\n",
    "            # Depending on the model, this might be different (e.g., [x1, y1, x2, y2]).\n",
    "            x1, y1 = int(bbox[0] - bbox[2] / 2), int(bbox[1] - bbox[3] / 2)\n",
    "            x2, y2 = int(bbox[0] + bbox[2] / 2), int(bbox[1] + bbox[3] / 2)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw the class and confidence score\n",
    "            label = f\"Class: {class_id}, Confidence: {class_score:.2f}\"\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8m.pt\") \n",
    "model.export(format=\"onnx\", imgsz=[480,640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[5.1777692e+00, 1.0288152e+01, 1.7757238e+01, ...,\n",
      "         5.3694403e+02, 5.7199719e+02, 5.8175946e+02],\n",
      "        [3.7307391e+00, 3.7775056e+00, 4.2060409e+00, ...,\n",
      "         4.2660059e+02, 4.1951974e+02, 4.0324100e+02],\n",
      "        [1.0757503e+01, 2.0699392e+01, 3.4478863e+01, ...,\n",
      "         2.6600211e+02, 2.8358252e+02, 2.6613248e+02],\n",
      "        ...,\n",
      "        [7.7486038e-07, 5.3644180e-07, 4.4703484e-07, ...,\n",
      "         1.6391277e-06, 2.0861626e-06, 1.9073486e-06],\n",
      "        [4.4703484e-07, 2.0861626e-07, 2.0861626e-07, ...,\n",
      "         2.0265579e-06, 2.2649765e-06, 2.1755695e-06],\n",
      "        [1.1920929e-06, 4.4703484e-07, 2.9802322e-07, ...,\n",
      "         1.9073486e-06, 2.1457672e-06, 2.1457672e-06]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "# ONNX 모델 로드\n",
    "ort_session = onnxruntime.InferenceSession(\"yolov8m.onnx\")\n",
    "\n",
    "# 입력 텐서 크기 설정\n",
    "input_shape = (1, 3, 480, 640)\n",
    "x = np.random.random(input_shape).astype(np.float32)\n",
    "\n",
    "# ONNX 런타임에서 입력 및 출력 이름 가져오기\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs()[0].name\n",
    "\n",
    "# ONNX 모델 실행\n",
    "result = ort_session.run([output_name], {input_name: x})\n",
    "\n",
    "# 결과 출력\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchFile",
     "evalue": "[ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from yolov8m.onnx failed:Load model yolov8m.onnx failed. File doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms\n\u001b[0;32m      7\u001b[0m \u001b[39m# ONNX 모델 로드\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m ort_session \u001b[39m=\u001b[39m onnxruntime\u001b[39m.\u001b[39;49mInferenceSession(\u001b[39m\"\u001b[39;49m\u001b[39myolov8m.onnx\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m \u001b[39m# ONNX 런타임에서 입력 및 출력 이름 가져오기\u001b[39;00m\n\u001b[0;32m     11\u001b[0m input_name \u001b[39m=\u001b[39m ort_session\u001b[39m.\u001b[39mget_inputs()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:383\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[1;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m disabled_optimizers \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mdisabled_optimizers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdisabled_optimizers\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 383\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_inference_session(providers, provider_options, disabled_optimizers)\n\u001b[0;32m    384\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    385\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_fallback:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:424\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[1;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[0;32m    422\u001b[0m session_options \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess_options \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess_options \u001b[39melse\u001b[39;00m C\u001b[39m.\u001b[39mget_default_session_options()\n\u001b[0;32m    423\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_path:\n\u001b[1;32m--> 424\u001b[0m     sess \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39;49mInferenceSession(session_options, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_path, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_config_from_model)\n\u001b[0;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    426\u001b[0m     sess \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39mInferenceSession(session_options, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_bytes, \u001b[39mFalse\u001b[39;00m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_config_from_model)\n",
      "\u001b[1;31mNoSuchFile\u001b[0m: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from yolov8m.onnx failed:Load model yolov8m.onnx failed. File doesn't exist"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# ONNX 모델 로드\n",
    "ort_session = onnxruntime.InferenceSession(\"yolov8m.onnx\")\n",
    "\n",
    "# ONNX 런타임에서 입력 및 출력 이름 가져오기\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs()[0].name\n",
    "\n",
    "# 웹캠을 사용하거나 비디오 파일을 읽기 위한 VideoCapture 생성\n",
    "cap = cv2.VideoCapture(0) # Use 0 for webcam, or replace with video file path\n",
    "\n",
    "# Open the file to save detection results\n",
    "f = open(\"object_locations.txt\", \"w\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # OpenCV는 BGR을 사용하지만, PyTorch는 RGB를 사용하므로 색상을 변환합니다.\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # 이미지를 PIL 이미지로 변환합니다.\n",
    "    pil_image = Image.fromarray(frame)\n",
    "    # 이미지를 모델 입력에 맞게 전처리 합니다.\n",
    "    # 모델 입력 크기에 따라 변경해야 합니다.\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((480, 640)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img = preprocess(pil_image)\n",
    "    img = img.unsqueeze(0).numpy()\n",
    "\n",
    "    # ONNX 모델 실행\n",
    "    # results = ort_session.run([output_name], {input_name: img})\n",
    "    results = ort_session.run([output_name], {input_name: img})\n",
    "    # 모델의 결과를 확인합니다.\n",
    "    print(f\"Model output shape: {results[0].shape}\")\n",
    "    print(f\"First detection output: {results[0][0]}\")\n",
    "\n",
    "    # Iterate over each detection\n",
    "    for detection in results[0]:\n",
    "        if detection[4] > 0.85:  # If the confidence score is greater than 0.85\n",
    "            f.write(f\"Class: {int(detection[5])}, BBox: {detection[:4]}\\n\")\n",
    "\n",
    "            # Draw the bounding box\n",
    "            x1, y1, x2, y2 = map(int, detection[:4])\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw the class and confidence score\n",
    "            label = f\"Class: {int(detection[5])}, Confidence: {detection[4]:.2f}\"\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "from yolov8 import YOLOv8\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize YOLOv7 object detector\n",
    "model_path = \"models/yolov8m.onnx\"\n",
    "yolov8_detector = YOLOv8(model_path, conf_thres=0.5, iou_thres=0.5)\n",
    "\n",
    "cv2.namedWindow(\"Detected Objects\", cv2.WINDOW_NORMAL)\n",
    "while cap.isOpened():\n",
    "\n",
    "    # Read frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Update object localizer\n",
    "    boxes, scores, class_ids = yolov8_detector(frame)\n",
    "\n",
    "    combined_img = yolov8_detector.draw_detections(frame)\n",
    "    cv2.imshow(\"Detected Objects\", combined_img)\n",
    "\n",
    "    # Press key q to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOV5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython>=3.1.30 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 5)) (3.1.32)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 6)) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 7)) (1.25.1)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 8)) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 9)) (9.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 10)) (5.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 13)) (1.11.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 16)) (0.15.2+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
      "Requirement already satisfied: ultralytics>=8.0.111 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 18)) (8.0.136)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 27)) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from -r requirements.txt (line 42)) (68.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3->-r requirements.txt (line 6)) (3.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 15)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 15)) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user\\miniconda3\\envs\\nic\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5.git\n",
    "# %cd yolov5\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-7-17 Python-3.9.17 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|██████████| 14.1M/14.1M [00:01<00:00, 9.48MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-7-17 Python-3.9.17 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 75.86\n",
      "FPS: 62.59\n",
      "FPS: 77.04\n",
      "FPS: 125.04\n",
      "FPS: 99.94\n",
      "FPS: 91.16\n",
      "FPS: 91.07\n",
      "FPS: 110.58\n",
      "FPS: 111.43\n",
      "FPS: 91.15\n",
      "FPS: 100.01\n",
      "FPS: 94.71\n",
      "FPS: 111.11\n",
      "FPS: 99.01\n",
      "FPS: 68.72\n",
      "FPS: 90.02\n",
      "FPS: 111.34\n",
      "FPS: 76.95\n",
      "FPS: 83.33\n",
      "FPS: 91.12\n",
      "FPS: 85.72\n",
      "FPS: 91.24\n",
      "FPS: 99.79\n",
      "FPS: 125.02\n",
      "FPS: 111.03\n",
      "FPS: 124.82\n",
      "FPS: 125.03\n",
      "FPS: 90.93\n",
      "FPS: 83.34\n",
      "FPS: 111.05\n",
      "FPS: 66.77\n",
      "FPS: 110.33\n",
      "FPS: 105.34\n",
      "FPS: 124.91\n",
      "FPS: 111.40\n",
      "FPS: 117.61\n",
      "FPS: 121.19\n",
      "FPS: 111.11\n",
      "FPS: 69.93\n",
      "FPS: 125.02\n",
      "FPS: 125.44\n",
      "FPS: 110.08\n",
      "FPS: 110.74\n",
      "FPS: 108.31\n",
      "FPS: 122.64\n",
      "FPS: 99.99\n",
      "FPS: 110.95\n",
      "FPS: 87.12\n",
      "FPS: 126.74\n",
      "FPS: 125.02\n",
      "FPS: 91.74\n",
      "FPS: 100.19\n",
      "FPS: 111.37\n",
      "FPS: 99.32\n",
      "FPS: 58.75\n",
      "FPS: 83.34\n",
      "FPS: 74.13\n",
      "FPS: 90.88\n",
      "FPS: 83.34\n",
      "FPS: 63.49\n",
      "FPS: 83.48\n",
      "FPS: 83.55\n",
      "FPS: 95.20\n",
      "FPS: 64.78\n",
      "FPS: 90.93\n",
      "FPS: 90.08\n",
      "FPS: 76.90\n",
      "FPS: 91.06\n",
      "FPS: 103.28\n",
      "FPS: 90.91\n",
      "FPS: 100.01\n",
      "FPS: 92.48\n",
      "FPS: 83.47\n",
      "FPS: 69.11\n",
      "FPS: 85.91\n",
      "FPS: 83.34\n",
      "FPS: 90.73\n",
      "FPS: 84.95\n",
      "FPS: 90.92\n",
      "FPS: 100.22\n",
      "FPS: 105.57\n",
      "FPS: 83.44\n",
      "FPS: 106.97\n",
      "FPS: 101.64\n",
      "FPS: 90.46\n",
      "FPS: 91.09\n",
      "FPS: 99.99\n",
      "FPS: 99.77\n",
      "FPS: 62.59\n",
      "FPS: 86.80\n",
      "FPS: 82.45\n",
      "FPS: 90.92\n",
      "FPS: 90.80\n",
      "FPS: 90.85\n",
      "FPS: 81.02\n",
      "FPS: 75.62\n",
      "FPS: 77.04\n",
      "FPS: 87.93\n",
      "FPS: 91.10\n",
      "FPS: 90.95\n",
      "FPS: 83.21\n",
      "FPS: 83.40\n",
      "FPS: 90.95\n",
      "FPS: 76.93\n",
      "FPS: 91.07\n",
      "FPS: 100.19\n",
      "FPS: 81.08\n",
      "FPS: 100.21\n",
      "FPS: 90.73\n",
      "FPS: 90.92\n",
      "FPS: 100.19\n",
      "FPS: 71.32\n",
      "FPS: 82.95\n",
      "FPS: 80.18\n",
      "FPS: 87.96\n",
      "FPS: 90.91\n",
      "FPS: 89.11\n",
      "FPS: 90.90\n",
      "FPS: 91.08\n",
      "FPS: 100.00\n",
      "FPS: 95.47\n",
      "FPS: 89.76\n",
      "FPS: 98.25\n",
      "FPS: 89.19\n",
      "FPS: 71.32\n",
      "FPS: 83.08\n",
      "FPS: 67.70\n",
      "FPS: 83.50\n",
      "FPS: 77.06\n",
      "FPS: 83.46\n",
      "FPS: 81.08\n",
      "FPS: 82.39\n",
      "FPS: 79.38\n",
      "FPS: 90.91\n",
      "FPS: 72.68\n",
      "FPS: 83.34\n",
      "FPS: 83.32\n",
      "FPS: 89.57\n",
      "FPS: 71.59\n",
      "FPS: 95.43\n",
      "FPS: 90.87\n",
      "FPS: 82.52\n",
      "FPS: 75.71\n",
      "FPS: 90.92\n",
      "FPS: 83.31\n",
      "FPS: 98.88\n",
      "FPS: 76.88\n",
      "FPS: 71.38\n",
      "FPS: 90.15\n",
      "FPS: 85.93\n",
      "FPS: 62.58\n",
      "FPS: 83.47\n",
      "FPS: 83.48\n",
      "FPS: 90.91\n",
      "FPS: 83.34\n",
      "FPS: 79.96\n",
      "FPS: 100.01\n",
      "FPS: 88.23\n",
      "FPS: 84.22\n",
      "FPS: 79.97\n",
      "FPS: 83.31\n",
      "FPS: 91.09\n",
      "FPS: 60.83\n",
      "FPS: 90.87\n",
      "FPS: 80.20\n",
      "FPS: 83.33\n",
      "FPS: 90.90\n",
      "FPS: 70.95\n",
      "FPS: 66.58\n",
      "FPS: 55.40\n",
      "FPS: 83.48\n",
      "FPS: 90.91\n",
      "FPS: 80.11\n",
      "FPS: 90.93\n",
      "FPS: 82.76\n",
      "FPS: 62.61\n",
      "FPS: 72.85\n",
      "FPS: 83.33\n",
      "FPS: 66.52\n",
      "FPS: 77.04\n",
      "FPS: 74.56\n",
      "FPS: 83.51\n",
      "FPS: 76.93\n",
      "FPS: 66.76\n",
      "FPS: 71.41\n",
      "FPS: 62.58\n",
      "FPS: 82.53\n",
      "FPS: 71.42\n",
      "FPS: 71.42\n",
      "FPS: 83.34\n",
      "FPS: 80.92\n",
      "FPS: 83.27\n",
      "FPS: 91.07\n",
      "FPS: 71.61\n",
      "FPS: 90.96\n",
      "FPS: 83.34\n",
      "FPS: 68.95\n",
      "FPS: 82.76\n",
      "FPS: 91.07\n",
      "FPS: 83.32\n",
      "FPS: 79.87\n",
      "FPS: 89.02\n",
      "FPS: 83.33\n",
      "FPS: 83.48\n",
      "FPS: 71.89\n",
      "FPS: 74.53\n",
      "FPS: 80.06\n",
      "FPS: 91.42\n",
      "FPS: 83.22\n",
      "FPS: 83.47\n",
      "FPS: 77.07\n",
      "FPS: 66.12\n",
      "FPS: 91.12\n",
      "FPS: 88.79\n",
      "FPS: 66.75\n",
      "FPS: 83.34\n",
      "FPS: 76.92\n",
      "FPS: 66.52\n",
      "FPS: 75.45\n",
      "FPS: 83.17\n",
      "FPS: 83.45\n",
      "FPS: 90.17\n",
      "FPS: 89.15\n",
      "FPS: 69.57\n",
      "FPS: 83.53\n",
      "FPS: 74.50\n",
      "FPS: 83.34\n",
      "FPS: 67.45\n",
      "FPS: 83.46\n",
      "FPS: 70.66\n",
      "FPS: 74.18\n",
      "FPS: 99.16\n",
      "FPS: 83.54\n",
      "FPS: 71.45\n",
      "FPS: 81.21\n",
      "FPS: 91.05\n",
      "FPS: 82.97\n",
      "FPS: 83.52\n",
      "FPS: 66.66\n",
      "FPS: 76.92\n",
      "FPS: 66.67\n",
      "FPS: 58.92\n",
      "FPS: 90.31\n",
      "FPS: 83.49\n",
      "FPS: 81.60\n",
      "FPS: 90.92\n",
      "FPS: 86.66\n",
      "FPS: 80.46\n",
      "FPS: 84.56\n",
      "FPS: 91.32\n",
      "FPS: 82.07\n",
      "FPS: 69.11\n",
      "FPS: 69.05\n",
      "FPS: 77.04\n",
      "FPS: 83.36\n",
      "FPS: 74.29\n",
      "FPS: 83.33\n",
      "FPS: 79.58\n",
      "FPS: 80.92\n",
      "FPS: 93.94\n",
      "FPS: 83.46\n",
      "FPS: 76.79\n",
      "FPS: 83.33\n",
      "FPS: 83.30\n",
      "FPS: 83.51\n",
      "FPS: 83.30\n",
      "FPS: 80.05\n",
      "FPS: 77.04\n",
      "FPS: 76.93\n",
      "FPS: 76.89\n",
      "FPS: 78.56\n",
      "FPS: 77.65\n",
      "FPS: 70.63\n",
      "FPS: 83.21\n",
      "FPS: 83.34\n",
      "FPS: 76.89\n",
      "FPS: 90.89\n",
      "FPS: 77.51\n",
      "FPS: 68.27\n",
      "FPS: 83.34\n",
      "FPS: 77.03\n",
      "FPS: 77.03\n",
      "FPS: 77.03\n",
      "FPS: 76.75\n",
      "FPS: 83.58\n",
      "FPS: 76.19\n",
      "FPS: 76.93\n",
      "FPS: 88.98\n",
      "FPS: 83.36\n",
      "FPS: 83.34\n",
      "FPS: 73.74\n",
      "FPS: 76.93\n",
      "FPS: 77.15\n",
      "FPS: 79.01\n",
      "FPS: 66.59\n",
      "FPS: 83.32\n",
      "FPS: 82.12\n",
      "FPS: 76.95\n",
      "FPS: 77.12\n",
      "FPS: 85.00\n",
      "FPS: 76.90\n",
      "FPS: 81.14\n",
      "FPS: 80.05\n",
      "FPS: 83.46\n",
      "FPS: 71.58\n",
      "FPS: 83.07\n",
      "FPS: 75.41\n",
      "FPS: 90.91\n",
      "FPS: 91.09\n",
      "FPS: 77.03\n",
      "FPS: 83.32\n",
      "FPS: 77.03\n",
      "FPS: 74.45\n",
      "FPS: 83.33\n",
      "FPS: 73.97\n",
      "FPS: 77.04\n",
      "FPS: 76.58\n",
      "FPS: 74.15\n",
      "FPS: 77.03\n",
      "FPS: 76.56\n",
      "FPS: 77.05\n",
      "FPS: 76.95\n",
      "FPS: 83.33\n",
      "FPS: 80.05\n",
      "FPS: 80.60\n",
      "FPS: 83.49\n",
      "FPS: 79.94\n",
      "FPS: 76.94\n",
      "FPS: 83.20\n",
      "FPS: 77.92\n",
      "FPS: 76.93\n",
      "FPS: 83.46\n",
      "FPS: 74.02\n",
      "FPS: 77.02\n",
      "FPS: 83.36\n",
      "FPS: 83.51\n",
      "FPS: 95.24\n",
      "FPS: 71.56\n",
      "FPS: 78.64\n",
      "FPS: 91.06\n",
      "FPS: 69.64\n",
      "FPS: 78.54\n",
      "FPS: 71.53\n",
      "FPS: 91.07\n",
      "FPS: 83.33\n",
      "FPS: 70.82\n",
      "FPS: 80.43\n",
      "FPS: 91.04\n",
      "FPS: 80.74\n",
      "FPS: 74.99\n",
      "FPS: 88.21\n",
      "FPS: 64.45\n",
      "FPS: 83.34\n",
      "FPS: 84.30\n",
      "FPS: 80.55\n",
      "FPS: 71.60\n",
      "FPS: 94.87\n",
      "FPS: 90.91\n",
      "FPS: 83.20\n",
      "FPS: 80.97\n",
      "FPS: 76.82\n",
      "FPS: 71.43\n",
      "FPS: 80.17\n",
      "FPS: 77.04\n",
      "FPS: 77.12\n",
      "FPS: 80.10\n",
      "FPS: 83.34\n",
      "FPS: 80.09\n",
      "FPS: 76.93\n",
      "FPS: 72.03\n",
      "FPS: 79.26\n",
      "FPS: 80.15\n",
      "FPS: 80.94\n",
      "FPS: 76.89\n",
      "FPS: 60.58\n",
      "FPS: 76.81\n",
      "FPS: 83.33\n",
      "FPS: 87.04\n",
      "FPS: 83.47\n",
      "FPS: 74.17\n",
      "FPS: 76.92\n",
      "FPS: 83.46\n",
      "FPS: 83.45\n",
      "FPS: 91.11\n",
      "FPS: 83.47\n",
      "FPS: 90.92\n",
      "FPS: 85.69\n",
      "FPS: 81.49\n",
      "FPS: 77.06\n",
      "FPS: 70.51\n",
      "FPS: 76.31\n",
      "FPS: 76.93\n",
      "FPS: 83.58\n",
      "FPS: 83.54\n",
      "FPS: 67.14\n",
      "FPS: 79.98\n",
      "FPS: 83.47\n",
      "FPS: 71.43\n",
      "FPS: 87.03\n",
      "FPS: 86.94\n",
      "FPS: 83.34\n",
      "FPS: 80.80\n",
      "FPS: 90.90\n",
      "FPS: 91.18\n",
      "FPS: 83.29\n",
      "FPS: 83.48\n",
      "FPS: 83.47\n",
      "FPS: 76.90\n",
      "FPS: 83.47\n",
      "FPS: 75.42\n",
      "FPS: 78.86\n",
      "FPS: 83.48\n",
      "FPS: 76.92\n",
      "FPS: 80.06\n",
      "FPS: 83.45\n",
      "FPS: 80.49\n",
      "FPS: 79.70\n",
      "FPS: 82.66\n",
      "FPS: 83.34\n",
      "FPS: 76.02\n",
      "FPS: 76.93\n",
      "FPS: 83.46\n",
      "FPS: 89.14\n",
      "FPS: 77.05\n",
      "FPS: 71.42\n",
      "FPS: 83.47\n",
      "FPS: 77.04\n",
      "FPS: 83.35\n",
      "FPS: 76.30\n",
      "FPS: 83.46\n",
      "FPS: 83.47\n",
      "FPS: 83.29\n",
      "FPS: 84.05\n",
      "FPS: 77.12\n",
      "FPS: 88.39\n",
      "FPS: 83.48\n",
      "FPS: 81.08\n",
      "FPS: 95.19\n",
      "FPS: 71.53\n",
      "FPS: 83.48\n",
      "FPS: 83.11\n",
      "FPS: 90.86\n",
      "FPS: 76.80\n",
      "FPS: 71.50\n",
      "FPS: 83.45\n",
      "FPS: 81.25\n",
      "FPS: 88.03\n",
      "FPS: 76.88\n",
      "FPS: 77.05\n",
      "FPS: 85.21\n",
      "FPS: 82.71\n",
      "FPS: 83.33\n",
      "FPS: 74.21\n",
      "FPS: 91.06\n",
      "FPS: 69.05\n",
      "FPS: 88.08\n",
      "FPS: 83.33\n",
      "FPS: 65.27\n",
      "FPS: 81.72\n",
      "FPS: 83.47\n",
      "FPS: 76.95\n",
      "FPS: 82.25\n",
      "FPS: 74.92\n",
      "FPS: 81.03\n",
      "FPS: 76.87\n",
      "FPS: 91.08\n",
      "FPS: 77.05\n",
      "FPS: 91.06\n",
      "FPS: 91.07\n",
      "FPS: 76.94\n",
      "FPS: 76.90\n",
      "FPS: 83.33\n",
      "FPS: 83.19\n",
      "FPS: 91.07\n",
      "FPS: 77.89\n",
      "FPS: 83.34\n",
      "FPS: 80.74\n",
      "FPS: 91.14\n",
      "FPS: 76.92\n",
      "FPS: 90.82\n",
      "FPS: 90.80\n",
      "FPS: 77.03\n",
      "FPS: 90.93\n",
      "FPS: 76.91\n",
      "FPS: 83.58\n",
      "FPS: 88.15\n",
      "FPS: 76.75\n",
      "FPS: 77.10\n",
      "FPS: 73.72\n",
      "FPS: 80.72\n",
      "FPS: 83.33\n",
      "FPS: 77.02\n",
      "FPS: 81.20\n",
      "FPS: 84.15\n",
      "FPS: 77.07\n",
      "FPS: 76.81\n",
      "FPS: 74.97\n",
      "FPS: 76.90\n",
      "FPS: 76.81\n",
      "FPS: 77.09\n",
      "FPS: 76.76\n",
      "FPS: 83.56\n",
      "FPS: 76.92\n",
      "FPS: 77.01\n",
      "FPS: 83.56\n",
      "FPS: 74.13\n",
      "FPS: 66.75\n",
      "FPS: 77.04\n",
      "FPS: 83.54\n",
      "FPS: 76.90\n",
      "FPS: 76.18\n",
      "FPS: 77.04\n",
      "FPS: 76.91\n",
      "FPS: 76.89\n",
      "FPS: 77.03\n",
      "FPS: 85.85\n",
      "FPS: 76.92\n",
      "FPS: 77.04\n",
      "FPS: 77.06\n",
      "FPS: 75.34\n",
      "FPS: 76.92\n",
      "FPS: 80.45\n",
      "FPS: 76.93\n",
      "FPS: 83.48\n",
      "FPS: 83.33\n",
      "FPS: 76.87\n",
      "FPS: 83.34\n",
      "FPS: 76.91\n",
      "FPS: 88.49\n",
      "FPS: 78.79\n",
      "FPS: 83.33\n",
      "FPS: 76.81\n",
      "FPS: 83.34\n",
      "FPS: 83.28\n",
      "FPS: 76.89\n",
      "FPS: 83.33\n",
      "FPS: 77.08\n",
      "FPS: 83.05\n",
      "FPS: 66.73\n",
      "FPS: 71.52\n",
      "FPS: 77.03\n",
      "FPS: 82.85\n",
      "FPS: 80.06\n",
      "FPS: 83.49\n",
      "FPS: 76.89\n",
      "FPS: 65.03\n",
      "FPS: 80.91\n",
      "FPS: 81.20\n",
      "FPS: 76.92\n",
      "FPS: 75.71\n",
      "FPS: 76.86\n",
      "FPS: 80.39\n",
      "FPS: 83.46\n",
      "FPS: 67.05\n",
      "FPS: 76.93\n",
      "FPS: 83.46\n",
      "FPS: 75.01\n",
      "FPS: 73.36\n",
      "FPS: 71.10\n",
      "FPS: 76.68\n",
      "FPS: 77.04\n",
      "FPS: 80.11\n",
      "FPS: 76.93\n",
      "FPS: 76.93\n",
      "FPS: 83.15\n",
      "FPS: 81.74\n",
      "FPS: 76.61\n",
      "FPS: 83.50\n",
      "FPS: 76.93\n",
      "FPS: 76.93\n",
      "FPS: 76.01\n",
      "FPS: 77.04\n",
      "FPS: 76.89\n",
      "FPS: 76.36\n",
      "FPS: 76.47\n",
      "FPS: 77.07\n",
      "FPS: 66.68\n",
      "FPS: 82.99\n",
      "FPS: 70.97\n",
      "FPS: 80.24\n",
      "FPS: 83.33\n",
      "FPS: 76.93\n",
      "FPS: 83.32\n",
      "FPS: 76.90\n",
      "FPS: 73.41\n",
      "FPS: 74.54\n",
      "FPS: 82.55\n",
      "FPS: 80.07\n",
      "FPS: 75.00\n",
      "FPS: 83.46\n",
      "FPS: 64.96\n",
      "FPS: 83.47\n",
      "FPS: 77.05\n",
      "FPS: 83.02\n",
      "FPS: 77.05\n",
      "FPS: 81.52\n",
      "FPS: 80.03\n",
      "FPS: 71.14\n",
      "FPS: 70.99\n",
      "FPS: 71.41\n",
      "FPS: 74.37\n",
      "FPS: 80.68\n",
      "FPS: 81.99\n",
      "FPS: 77.03\n",
      "FPS: 83.20\n",
      "FPS: 76.76\n",
      "FPS: 76.40\n",
      "FPS: 76.93\n",
      "FPS: 79.03\n",
      "FPS: 76.73\n",
      "FPS: 76.16\n",
      "FPS: 71.41\n",
      "FPS: 76.92\n",
      "FPS: 77.03\n",
      "FPS: 80.78\n",
      "FPS: 76.92\n",
      "FPS: 83.34\n",
      "FPS: 83.18\n",
      "FPS: 76.84\n",
      "FPS: 76.92\n",
      "FPS: 74.18\n",
      "FPS: 87.09\n",
      "FPS: 77.04\n",
      "FPS: 82.96\n",
      "FPS: 77.03\n",
      "FPS: 83.17\n",
      "FPS: 75.64\n",
      "FPS: 80.05\n",
      "FPS: 77.03\n",
      "FPS: 83.07\n",
      "FPS: 90.92\n",
      "FPS: 83.52\n",
      "FPS: 83.42\n",
      "FPS: 80.64\n",
      "FPS: 77.02\n",
      "FPS: 83.75\n",
      "FPS: 83.29\n",
      "FPS: 77.03\n",
      "FPS: 83.43\n",
      "FPS: 76.92\n",
      "FPS: 83.30\n",
      "FPS: 80.05\n",
      "FPS: 90.87\n",
      "FPS: 91.74\n",
      "FPS: 83.54\n",
      "FPS: 83.59\n",
      "FPS: 71.85\n",
      "FPS: 77.60\n",
      "FPS: 76.93\n",
      "FPS: 87.08\n",
      "FPS: 70.73\n",
      "FPS: 82.04\n",
      "FPS: 77.04\n",
      "FPS: 78.86\n",
      "FPS: 83.60\n",
      "FPS: 83.32\n",
      "FPS: 78.61\n",
      "FPS: 83.40\n",
      "FPS: 90.91\n",
      "FPS: 76.28\n",
      "FPS: 83.33\n",
      "FPS: 81.95\n",
      "FPS: 87.60\n",
      "FPS: 83.34\n",
      "FPS: 83.35\n",
      "FPS: 80.08\n",
      "FPS: 83.20\n",
      "FPS: 88.22\n",
      "FPS: 82.90\n",
      "FPS: 77.10\n",
      "FPS: 74.77\n",
      "FPS: 71.40\n",
      "FPS: 71.32\n",
      "FPS: 69.33\n",
      "FPS: 71.52\n",
      "FPS: 65.09\n",
      "FPS: 70.86\n",
      "FPS: 62.57\n",
      "FPS: 76.85\n",
      "FPS: 77.04\n",
      "FPS: 70.52\n",
      "FPS: 71.53\n",
      "FPS: 74.75\n",
      "FPS: 80.14\n",
      "FPS: 71.44\n",
      "FPS: 83.30\n",
      "FPS: 55.63\n",
      "FPS: 76.92\n",
      "FPS: 76.46\n",
      "FPS: 76.93\n",
      "FPS: 83.30\n",
      "FPS: 76.92\n",
      "FPS: 69.04\n",
      "FPS: 75.08\n",
      "FPS: 76.92\n",
      "FPS: 87.11\n",
      "FPS: 76.93\n",
      "FPS: 76.92\n",
      "FPS: 83.35\n",
      "FPS: 76.95\n",
      "FPS: 83.34\n",
      "FPS: 91.12\n",
      "FPS: 76.93\n",
      "FPS: 77.04\n",
      "FPS: 68.94\n",
      "FPS: 79.17\n",
      "FPS: 80.38\n",
      "FPS: 83.09\n",
      "FPS: 71.55\n",
      "FPS: 77.13\n",
      "FPS: 90.87\n",
      "FPS: 83.30\n",
      "FPS: 83.34\n",
      "FPS: 83.33\n",
      "FPS: 76.97\n",
      "FPS: 77.00\n",
      "FPS: 78.76\n",
      "FPS: 77.00\n",
      "FPS: 76.92\n",
      "FPS: 62.30\n",
      "FPS: 76.73\n",
      "FPS: 74.51\n",
      "FPS: 81.53\n",
      "FPS: 83.47\n",
      "FPS: 71.43\n",
      "FPS: 71.57\n",
      "FPS: 90.36\n",
      "FPS: 77.12\n",
      "FPS: 77.60\n",
      "FPS: 75.21\n",
      "FPS: 77.08\n",
      "FPS: 79.83\n",
      "FPS: 90.91\n",
      "FPS: 71.99\n",
      "FPS: 74.90\n",
      "FPS: 90.90\n",
      "FPS: 83.47\n",
      "FPS: 76.04\n",
      "FPS: 83.33\n",
      "FPS: 70.06\n",
      "FPS: 90.87\n",
      "FPS: 67.06\n",
      "FPS: 80.12\n",
      "FPS: 82.33\n",
      "FPS: 76.85\n",
      "FPS: 82.87\n",
      "FPS: 70.78\n",
      "FPS: 77.55\n",
      "FPS: 87.93\n",
      "FPS: 76.27\n",
      "FPS: 87.88\n",
      "FPS: 90.91\n",
      "FPS: 83.10\n",
      "FPS: 80.20\n",
      "FPS: 91.07\n",
      "FPS: 91.87\n",
      "FPS: 83.28\n",
      "FPS: 100.32\n",
      "FPS: 83.32\n",
      "FPS: 81.02\n",
      "FPS: 83.46\n",
      "FPS: 91.05\n",
      "FPS: 74.86\n",
      "FPS: 76.94\n",
      "FPS: 90.86\n",
      "FPS: 90.91\n",
      "FPS: 71.53\n",
      "FPS: 83.28\n",
      "FPS: 83.35\n",
      "FPS: 91.11\n",
      "FPS: 87.53\n",
      "FPS: 90.91\n",
      "FPS: 76.93\n",
      "FPS: 91.10\n",
      "FPS: 76.93\n",
      "FPS: 83.48\n",
      "FPS: 91.07\n",
      "FPS: 76.94\n",
      "FPS: 71.53\n",
      "FPS: 76.56\n",
      "FPS: 80.80\n",
      "FPS: 76.91\n",
      "FPS: 90.88\n",
      "FPS: 83.46\n",
      "FPS: 71.78\n",
      "FPS: 83.44\n",
      "FPS: 71.43\n",
      "FPS: 71.44\n",
      "FPS: 83.35\n",
      "FPS: 84.21\n",
      "FPS: 81.15\n",
      "FPS: 91.04\n",
      "FPS: 83.46\n",
      "FPS: 66.57\n",
      "FPS: 71.29\n",
      "FPS: 83.29\n",
      "FPS: 90.34\n",
      "FPS: 81.91\n",
      "FPS: 91.10\n",
      "FPS: 77.04\n",
      "FPS: 91.08\n",
      "FPS: 83.33\n",
      "FPS: 75.62\n",
      "FPS: 80.59\n",
      "FPS: 77.04\n",
      "FPS: 76.92\n",
      "FPS: 77.02\n",
      "FPS: 71.58\n",
      "FPS: 87.32\n",
      "FPS: 91.06\n",
      "FPS: 87.08\n",
      "FPS: 90.73\n",
      "FPS: 81.07\n",
      "FPS: 94.90\n",
      "FPS: 83.35\n",
      "FPS: 80.52\n",
      "FPS: 91.95\n",
      "FPS: 77.03\n",
      "FPS: 73.95\n",
      "FPS: 83.34\n",
      "FPS: 89.41\n",
      "FPS: 91.05\n",
      "FPS: 82.39\n",
      "FPS: 83.34\n",
      "FPS: 77.12\n",
      "FPS: 80.05\n",
      "FPS: 89.37\n",
      "FPS: 90.91\n",
      "FPS: 77.03\n",
      "FPS: 83.48\n",
      "FPS: 83.46\n",
      "FPS: 90.86\n",
      "FPS: 71.52\n",
      "FPS: 83.45\n",
      "FPS: 76.81\n",
      "FPS: 83.34\n",
      "FPS: 83.59\n",
      "FPS: 78.65\n",
      "FPS: 83.34\n",
      "FPS: 91.06\n",
      "FPS: 82.78\n",
      "FPS: 80.79\n",
      "FPS: 83.08\n",
      "FPS: 88.37\n",
      "FPS: 77.74\n",
      "FPS: 81.50\n",
      "FPS: 93.17\n",
      "FPS: 78.10\n",
      "FPS: 72.00\n",
      "FPS: 92.37\n",
      "FPS: 76.98\n",
      "FPS: 80.29\n",
      "FPS: 90.77\n",
      "FPS: 83.46\n",
      "FPS: 83.47\n",
      "FPS: 82.33\n",
      "FPS: 80.12\n",
      "FPS: 80.64\n",
      "FPS: 91.08\n",
      "FPS: 71.40\n",
      "FPS: 83.49\n",
      "FPS: 87.03\n",
      "FPS: 69.60\n",
      "FPS: 94.65\n",
      "FPS: 86.38\n",
      "FPS: 90.72\n",
      "FPS: 83.34\n",
      "FPS: 82.42\n",
      "FPS: 80.96\n",
      "FPS: 76.94\n",
      "FPS: 95.11\n",
      "FPS: 76.94\n",
      "FPS: 83.30\n",
      "FPS: 96.26\n",
      "FPS: 76.92\n",
      "FPS: 90.92\n",
      "FPS: 90.59\n",
      "FPS: 83.47\n",
      "FPS: 84.16\n",
      "FPS: 91.07\n",
      "FPS: 91.09\n",
      "FPS: 71.53\n",
      "FPS: 81.82\n",
      "FPS: 91.84\n",
      "FPS: 82.72\n",
      "FPS: 90.86\n",
      "FPS: 77.03\n",
      "FPS: 84.07\n",
      "FPS: 86.22\n",
      "FPS: 90.90\n",
      "FPS: 84.11\n",
      "FPS: 95.20\n",
      "FPS: 74.14\n",
      "FPS: 83.17\n",
      "FPS: 95.11\n",
      "FPS: 86.28\n",
      "FPS: 83.46\n",
      "FPS: 82.55\n",
      "FPS: 81.37\n",
      "FPS: 76.89\n",
      "FPS: 87.51\n",
      "FPS: 83.47\n",
      "FPS: 83.46\n",
      "FPS: 68.86\n",
      "FPS: 73.71\n",
      "FPS: 79.77\n",
      "FPS: 76.88\n",
      "FPS: 74.12\n",
      "FPS: 71.43\n",
      "FPS: 76.58\n",
      "FPS: 90.91\n",
      "FPS: 83.50\n",
      "FPS: 80.15\n",
      "FPS: 91.06\n",
      "FPS: 83.20\n",
      "FPS: 83.34\n",
      "FPS: 90.92\n",
      "FPS: 83.19\n",
      "FPS: 80.07\n",
      "FPS: 87.53\n",
      "FPS: 87.58\n",
      "FPS: 86.67\n",
      "FPS: 80.34\n",
      "FPS: 87.00\n",
      "FPS: 80.06\n",
      "FPS: 77.03\n",
      "FPS: 90.93\n",
      "FPS: 74.06\n",
      "FPS: 83.33\n",
      "FPS: 83.33\n",
      "FPS: 80.14\n",
      "FPS: 83.34\n",
      "FPS: 83.31\n",
      "FPS: 78.10\n",
      "FPS: 81.07\n",
      "FPS: 76.96\n",
      "FPS: 75.70\n",
      "FPS: 71.43\n",
      "FPS: 83.46\n",
      "FPS: 78.14\n",
      "FPS: 77.03\n",
      "FPS: 89.20\n",
      "FPS: 81.11\n",
      "FPS: 71.43\n",
      "FPS: 88.95\n",
      "FPS: 74.86\n",
      "FPS: 78.05\n",
      "FPS: 87.92\n",
      "FPS: 79.96\n",
      "FPS: 76.15\n",
      "FPS: 83.34\n",
      "FPS: 83.28\n",
      "FPS: 84.89\n",
      "FPS: 83.53\n",
      "FPS: 90.83\n",
      "FPS: 83.17\n",
      "FPS: 71.40\n",
      "FPS: 81.40\n",
      "FPS: 71.54\n",
      "FPS: 77.03\n",
      "FPS: 86.47\n",
      "FPS: 83.48\n",
      "FPS: 90.59\n",
      "FPS: 78.21\n",
      "FPS: 91.02\n",
      "FPS: 83.37\n",
      "FPS: 77.62\n",
      "FPS: 86.68\n",
      "FPS: 87.71\n",
      "FPS: 78.57\n",
      "FPS: 77.04\n",
      "FPS: 76.60\n",
      "FPS: 70.74\n",
      "FPS: 83.48\n",
      "FPS: 80.26\n",
      "FPS: 77.04\n",
      "FPS: 90.83\n",
      "FPS: 90.94\n",
      "FPS: 68.61\n",
      "FPS: 83.51\n",
      "FPS: 75.21\n",
      "FPS: 77.02\n",
      "FPS: 83.18\n",
      "FPS: 79.43\n",
      "FPS: 77.12\n",
      "FPS: 80.36\n",
      "FPS: 70.88\n",
      "FPS: 76.93\n",
      "FPS: 77.03\n",
      "FPS: 76.11\n",
      "FPS: 76.92\n",
      "FPS: 90.48\n",
      "FPS: 77.04\n",
      "FPS: 74.36\n",
      "FPS: 74.18\n",
      "FPS: 84.91\n",
      "FPS: 71.53\n",
      "FPS: 77.04\n",
      "FPS: 77.04\n",
      "FPS: 90.92\n",
      "FPS: 77.03\n",
      "FPS: 74.54\n",
      "FPS: 71.40\n",
      "FPS: 77.09\n",
      "FPS: 83.30\n",
      "FPS: 78.47\n",
      "FPS: 74.42\n",
      "FPS: 83.30\n",
      "FPS: 81.88\n",
      "FPS: 71.52\n",
      "FPS: 83.46\n",
      "FPS: 80.05\n",
      "FPS: 77.04\n",
      "FPS: 90.79\n",
      "FPS: 80.06\n",
      "FPS: 71.57\n",
      "FPS: 76.92\n",
      "FPS: 71.40\n",
      "FPS: 77.03\n",
      "FPS: 86.88\n",
      "FPS: 77.04\n",
      "FPS: 71.43\n",
      "FPS: 76.90\n",
      "FPS: 76.92\n",
      "FPS: 83.56\n",
      "FPS: 76.84\n",
      "FPS: 74.14\n",
      "FPS: 66.67\n",
      "FPS: 83.29\n",
      "FPS: 71.55\n",
      "FPS: 77.07\n",
      "FPS: 77.03\n",
      "FPS: 77.04\n",
      "FPS: 76.92\n",
      "FPS: 76.75\n",
      "FPS: 76.81\n",
      "FPS: 75.65\n",
      "FPS: 76.75\n",
      "FPS: 76.80\n",
      "FPS: 66.66\n",
      "FPS: 76.80\n",
      "FPS: 88.19\n",
      "FPS: 76.93\n",
      "FPS: 80.06\n",
      "FPS: 71.53\n",
      "FPS: 76.83\n",
      "FPS: 66.74\n",
      "FPS: 68.95\n",
      "FPS: 76.95\n",
      "FPS: 66.61\n",
      "FPS: 80.44\n",
      "FPS: 90.82\n",
      "FPS: 80.21\n",
      "FPS: 83.37\n",
      "FPS: 83.30\n",
      "FPS: 88.49\n",
      "FPS: 81.38\n",
      "FPS: 83.60\n",
      "FPS: 76.95\n",
      "FPS: 76.54\n",
      "FPS: 76.32\n",
      "FPS: 80.94\n",
      "FPS: 91.07\n",
      "FPS: 83.33\n",
      "FPS: 70.97\n",
      "FPS: 81.40\n",
      "FPS: 76.92\n",
      "FPS: 76.25\n",
      "FPS: 89.90\n",
      "FPS: 81.25\n",
      "FPS: 83.43\n",
      "FPS: 90.91\n",
      "FPS: 83.48\n",
      "FPS: 81.15\n",
      "FPS: 74.76\n",
      "FPS: 66.59\n",
      "FPS: 81.83\n",
      "FPS: 83.37\n",
      "FPS: 76.93\n",
      "FPS: 91.16\n",
      "FPS: 76.23\n",
      "FPS: 77.03\n",
      "FPS: 76.41\n",
      "FPS: 79.64\n",
      "FPS: 90.88\n",
      "FPS: 90.78\n",
      "FPS: 83.35\n",
      "FPS: 71.05\n",
      "FPS: 76.12\n",
      "FPS: 87.48\n",
      "FPS: 77.70\n",
      "FPS: 76.92\n",
      "FPS: 76.93\n",
      "FPS: 74.90\n",
      "FPS: 83.47\n",
      "FPS: 76.92\n",
      "FPS: 82.77\n",
      "FPS: 83.45\n",
      "FPS: 75.28\n",
      "FPS: 76.54\n",
      "FPS: 91.08\n",
      "FPS: 91.09\n",
      "FPS: 70.33\n",
      "FPS: 90.91\n",
      "FPS: 82.65\n",
      "FPS: 77.10\n",
      "FPS: 77.04\n",
      "FPS: 82.63\n",
      "FPS: 76.90\n",
      "FPS: 82.62\n",
      "FPS: 74.31\n",
      "FPS: 80.34\n",
      "FPS: 77.02\n",
      "FPS: 83.33\n",
      "FPS: 71.55\n",
      "FPS: 90.04\n",
      "FPS: 70.31\n",
      "FPS: 76.89\n",
      "FPS: 77.07\n",
      "FPS: 69.76\n",
      "FPS: 71.52\n",
      "FPS: 71.52\n",
      "FPS: 77.04\n",
      "FPS: 83.47\n",
      "FPS: 66.68\n",
      "FPS: 81.40\n",
      "FPS: 78.98\n",
      "FPS: 77.04\n",
      "FPS: 86.87\n",
      "FPS: 76.92\n",
      "FPS: 90.91\n",
      "FPS: 76.59\n",
      "FPS: 76.80\n",
      "FPS: 74.50\n",
      "FPS: 77.30\n",
      "FPS: 77.04\n",
      "FPS: 61.98\n",
      "FPS: 90.88\n",
      "FPS: 76.90\n",
      "FPS: 83.31\n",
      "FPS: 76.84\n",
      "FPS: 82.23\n",
      "FPS: 66.76\n",
      "FPS: 86.70\n",
      "FPS: 76.94\n",
      "FPS: 77.04\n",
      "FPS: 85.83\n",
      "FPS: 80.01\n",
      "FPS: 76.94\n",
      "FPS: 68.17\n",
      "FPS: 76.92\n",
      "FPS: 83.33\n",
      "FPS: 79.22\n",
      "FPS: 71.57\n",
      "FPS: 79.94\n",
      "FPS: 79.96\n",
      "FPS: 83.47\n",
      "FPS: 77.08\n",
      "FPS: 80.13\n",
      "FPS: 79.52\n",
      "FPS: 83.35\n",
      "FPS: 69.26\n",
      "FPS: 72.01\n",
      "FPS: 77.13\n",
      "FPS: 66.89\n",
      "FPS: 83.45\n",
      "FPS: 75.94\n",
      "FPS: 76.47\n",
      "FPS: 66.64\n",
      "FPS: 87.85\n",
      "FPS: 77.56\n",
      "FPS: 70.15\n",
      "FPS: 76.99\n",
      "FPS: 77.04\n",
      "FPS: 77.11\n",
      "FPS: 80.30\n",
      "FPS: 76.84\n",
      "FPS: 76.47\n",
      "FPS: 69.78\n",
      "FPS: 71.73\n",
      "FPS: 71.52\n",
      "FPS: 62.57\n",
      "FPS: 77.10\n",
      "FPS: 72.24\n",
      "FPS: 64.74\n",
      "FPS: 67.81\n",
      "FPS: 76.91\n",
      "FPS: 70.14\n",
      "FPS: 80.16\n",
      "FPS: 76.89\n",
      "FPS: 83.34\n",
      "FPS: 87.06\n",
      "FPS: 74.02\n",
      "FPS: 83.17\n",
      "FPS: 86.56\n",
      "FPS: 66.58\n",
      "FPS: 83.38\n",
      "FPS: 67.30\n",
      "FPS: 76.80\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Load the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s').to(device)  # use the appropriate model\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    # Convert to PIL Image\n",
    "    img = Image.fromarray(frame)\n",
    "\n",
    "    # Perform inference\n",
    "    start_time = time.time()\n",
    "    results = model(img)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    # Compute FPS (Frames Per Second)\n",
    "    fps = 1.0 / inference_time\n",
    "\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    annotated_image = results.render()\n",
    "    annotated_image = annotated_image[0]  # if using yolov5s, else remove this line\n",
    "\n",
    "    # Print inference time and FPS\n",
    "    # print(f'Inference time: {inference_time:.2f}s')\n",
    "    print(f'FPS: {fps:.2f}')\n",
    "\n",
    "    # Convert to BGR format for display\n",
    "    # annotated_image = cv2.cvtColor(annotated_image)\n",
    "    # but cv2 does not need this\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('YOLOv5 Object Detection', annotated_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPROT AS ONXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-7-17 Python-3.9.17 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|██████████| 14.1M/14.1M [00:03<00:00, 4.89MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "C:\\Users\\user/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:515: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
      "C:\\Users\\user/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\yolo.py:64: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2,torch\n",
    "# Check if CUDA is available and if so, use it\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # Load the model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s').to(device)\n",
    "# Prepare the dummy input\n",
    "dummy_input = torch.randn(1, 3, 640, 640).to(device)\n",
    "# Export the model to an ONNX file with do_constant_folding=False\n",
    "torch.onnx.export(model, dummy_input, \"test.onnx\", verbose=True, opset_version=16, do_constant_folding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-7-18 Python-3.9.17 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "from yolov5 import YOLOv5\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a YOLOv5 model\n",
    "model = YOLOv5(\"yolov5s.pt\")\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "# These are the class names for the COCO dataset used by YOLOv5. If you are using a custom model, replace these names with your actual class names.\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop_sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Open the file to save detection results\n",
    "f = open(\"object_locations_yolov5.txt\", \"w\")\n",
    "\n",
    "# Performance metrics\n",
    "tp, fp, fn = 0, 0, 0\n",
    "\n",
    "while True:\n",
    "    # Read one frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Predict using the YOLO model\n",
    "    results = model.predict(frame)\n",
    "    detections = results.pred[0]  # Use the 'pred' attribute to get the detections\n",
    "\n",
    "    # Iterate over each detection\n",
    "    for *bbox, confidence, class_id in detections:\n",
    "        # The detection coordinates are normalized, i.e., they are in the range [0, 1].\n",
    "        # Therefore, we need to multiply them by the width and height of the frame to convert them to pixel values.\n",
    "        x_center, y_center, width, height = map(lambda x: int(x * frame.shape[1] if x < 2 else x * frame.shape[0]), bbox)\n",
    "        class_id = int(class_id)\n",
    "\n",
    "        # We will consider the detection valid if the confidence score is greater than 0.85\n",
    "        if confidence > 0.85:\n",
    "            # Write to file\n",
    "            f.write(f\"Class: {class_id}, BBox: {[x_center, y_center, width, height]}\\n\")\n",
    "\n",
    "            # Draw the bounding box\n",
    "            x1, y1, x2, y2 = x_center - width // 2, y_center - height // 2, x_center + width // 2, y_center + height // 2\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw the class and confidence score\n",
    "            class_name = class_names[class_id]\n",
    "            label = f\"{class_name}: {confidence:.2f}\"\n",
    "\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # For performance metrics, you will need ground truth data for each frame.\n",
    "            # This data is usually not available in a live webcam feed.\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONLY PERSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-7-18 Python-3.9.17 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "c:\\Users\\user\\miniconda3\\envs\\nic\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "from yolov5 import YOLOv5\n",
    "import cv2\n",
    "\n",
    "# Create a YOLOv5 model\n",
    "model = YOLOv5(\"yolov5s.pt\")\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# These are the class names for the COCO dataset used by YOLOv5.\n",
    "class_names = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop_sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# Open the file to save detection results\n",
    "f = open(\"person_locations_yolov5.txt\", \"w\")\n",
    "\n",
    "while True:\n",
    "    # Read one frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Predict using the YOLO model\n",
    "    results = model.predict(frame)\n",
    "    detections = results.pred[0]  # Use the 'pred' attribute to get the detections\n",
    "\n",
    "    # Iterate over each detection\n",
    "    for *bbox, confidence, class_id in detections:\n",
    "        x_center, y_center, width, height = map(lambda x: int(x * frame.shape[1] if x < 2 else x * frame.shape[0]), bbox)\n",
    "        class_id = int(class_id)\n",
    "\n",
    "        # We will only consider the detection valid if the confidence score is greater than 0.85 and the class_id corresponds to 'person'\n",
    "        if confidence > 0.85 and class_id == class_names.index('person'):\n",
    "            # Write to file\n",
    "            f.write(f\"Class: {class_id}, BBox: {[x_center, y_center, width, height]}\\n\")\n",
    "\n",
    "            # Draw the bounding box\n",
    "            x1, y1, x2, y2 = x_center - width // 2, y_center - height // 2, x_center + width // 2, y_center + height // 2\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw the class and confidence score\n",
    "            class_name = class_names[class_id]\n",
    "            label = f\"{class_name}: {confidence:.2f}\"\n",
    "\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
