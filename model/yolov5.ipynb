{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_session = onnxruntime.InferenceSession(\"test.onnx\")\n",
    "\n",
    "# Load and prepare image\n",
    "image = cv2.imread(\"C:/Users/user/Desktop/human.jpg\")  # Path to the image file\n",
    "orig_image = cv2.resize(image, (640, 640))  # Resize image to 640x640\n",
    "image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)  # Convert color space from BGR to RGB\n",
    "image = image / 255.0  # Normalize pixel values (range [0, 1])\n",
    "image = np.transpose(image, (2, 0, 1))  # Change image shape from (H, W, C) to (C, H, W)\n",
    "image = np.expand_dims(image, axis=0).astype(np.float32)  # Add batch dimension and convert to float32\n",
    "\n",
    "# Run the model with the processed image\n",
    "outputs = onnx_session.run(None, {'onnx::Cast_0': image})\n",
    "\n",
    "# outputs is a list of all the model's output tensors\n",
    "output = outputs[0]  # Get the first output\n",
    "\n",
    "# output processing\n",
    "boxes = output[0, :, :4]\n",
    "confidences = output[0, :, 4]\n",
    "class_probs = output[0, :, 5:]\n",
    "\n",
    "# Get class IDs\n",
    "class_ids = np.argmax(class_probs, axis=1)\n",
    "\n",
    "# Thresholds\n",
    "confidence_threshold = 0.5\n",
    "class_threshold = 0.5\n",
    "\n",
    "# Get the class probabilities for the detected class IDs\n",
    "class_confidences = class_probs[np.arange(len(class_probs)), class_ids]\n",
    "\n",
    "# Iterate over the detections\n",
    "for box, confidence, class_confidence, class_id in zip(boxes, confidences, class_confidences, class_ids):\n",
    "    if confidence > confidence_threshold and class_confidence > class_threshold and class_id == 0:\n",
    "        x, y, w, h = box\n",
    "        x, y, w, h = int(x * 640), int(y * 640), int(w * 640), int(h * 640)  # Scale box to image's size\n",
    "        cv2.rectangle(orig_image, (x, y), (x+w, y+h), (0, 255, 0), 2)  # Draw bounding box\n",
    "\n",
    "cv2.imshow(\"Detection\", orig_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't receive frame. Exiting ...\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_session = onnxruntime.InferenceSession(\"test.onnx\")\n",
    "\n",
    "# Open video file\n",
    "video = cv2.VideoCapture('C:/Users/user/Desktop/video.mp4')\n",
    "\n",
    "# Open a csv file to write detections\n",
    "with open('detections.csv', mode='w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"frame_number\",\"class_id\",\"confidence\",\"x\",\"y\",\"w\",\"h\"])\n",
    "\n",
    "    # Frame counter\n",
    "    frame_number = 0\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame. Exiting ...\")\n",
    "            break\n",
    "\n",
    "        # Prepare the frame to input the network\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_resized = cv2.resize(frame_rgb, (640, 640)) / 255.0\n",
    "        frame_input = np.transpose(frame_resized, (2, 0, 1))\n",
    "        frame_input = np.expand_dims(frame_input, axis=0).astype(np.float32)\n",
    "\n",
    "        # Run the model with the frame\n",
    "        outputs = onnx_session.run(None, {'onnx::Cast_0': frame_input})\n",
    "\n",
    "        # Process the output\n",
    "        boxes = outputs[0][0, :, :4]\n",
    "        confidences = outputs[0][0, :, 4]\n",
    "        class_ids = np.argmax(outputs[0][0, :, 5:], axis=-1)\n",
    "\n",
    "        confidence_threshold = 0.5\n",
    "        class_threshold = 0.5\n",
    "\n",
    "        # Iterate over the detections\n",
    "        for box, confidence, class_id in zip(boxes, confidences, class_ids):\n",
    "            if confidence > confidence_threshold and class_id == 0:  # if class_id is \"person\" and confidence > threshold\n",
    "                x, y, w, h = box\n",
    "                x, y, w, h = int(x * 640), int(y * 640), int(w * 640), int(h * 640)  # Scale box to image's size\n",
    "                writer.writerow([frame_number, class_id, confidence, x, y, w, h])\n",
    "\n",
    "        frame_number += 1\n",
    "\n",
    "# Release everything\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
